{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://githubtocolab.com/Astolfo2332/white_paper_LoRa/blob/main/LoRa_Ananysis.ipynb\" target=\"_parent\\\">\n",
    "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" > </a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q94HzSJnnAv3"
   },
   "source": [
    "<div style=\"display: flex; align-items: center;\">\n",
    "    <div>\n",
    "        <h2>Actividad WhitePapers</h2>\n",
    "        <h2>Miguel López</h2>\n",
    "        <h2>ID 1001014378</h2>\n",
    "    </div>\n",
    "    <img src=\"https://yt3.ggpht.com/-10IUL9wra6k/AAAAAAAAAAI/AAAAAAAAAAA/UOBLu1uYOOE/s900-c-k-no/photo.jpg\" alt=\"Image description\" width=\"200\" style=\"margin-left: 20px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71EJSdOenAv3"
   },
   "source": [
    "# Una pequeña introducción a los transformers. LoRa, QLoRa y sus efectos en el fine-tuning de Large Language Models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfFBMMMMnAv4"
   },
   "source": [
    "# 1. Introducción\n",
    "Gracias al gran éxito de los Transformers, en especial de chatGPT por OpenAI y el gran interés por la industria en adoptar estas nuevas tecnologías, se ha generado la necesidad de modelos más exactos para diferentes casos de uso a nivel profesional. Para ello tradicionalmente se realizaba un reentrenamiento supervisado (con datos etiquetados) completo de los modelos, el cual podía dar a luz problemas como la pérdida de memoria del modelo para otras tareas [1] o principalmente el gran gasto computacional que implica entrenar un modelo, como por ejemplo GPT 3, el cual fue entrenado con 175 billones de parámetros [2]. Además, a diferencia de algunas técnicas de Deep learning, no se puede aplicar simplemente un entrenamiento a las capas superficiales del modelo ya que por la naturaleza de los Transformers, reentrenar su ventana de atención, en otras palabras lo que le permite a estos modelos tener una coherencia de ideas con un texto dado, podria generar pérdida en las capacidades generales del modelo [3]. Para dar solución a todo esto en 2021 se presentó LoRa o Low-Rank Adaptation of Large Language Models [2], donde a través de una adición de una pequeña matriz en capas especificas del modelo se podría reentrenar este a un costo computacional menor, sin perder la mayoría de sus cualidades generales como Large Lenaguage Models (LLM) y sucapacidad de respuestas más precisas dado casos establecidos.\n",
    "\n",
    "\n",
    "En lo relacionado a términos de optimización de memoria se puede combinar con técnicas como cuantización para bajar el grado de precisión de los pesos flotantes de los modelos de 32 bits a 16, 8 o 4 bits al mismo tiempo que se realiza un fine-tuning con LoRa, conocido como QLoRA [4], perdiendo un poco de precisión en el momento de sus respuestas, pero dejando las puertas abiertas a aplicaciones en por ejemplo teléfonos celulares o sistemas embebidos(por su reducción en el uso de memoría ) para su uso como productos funcionales.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XJgBPqVnAv4"
   },
   "source": [
    "# 2 Funcionamiento de Transformers y sus implicaciones.\n",
    "\n",
    "Los transfomers parten de la idea del como mantener la atención de un modelo a lo largo de sus neuronas sin perder ese foco de atención entre ellas. Usando la arquitectura de la forma:\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/Astolfo2332/white_paper_LoRa/main/images/transformers.png\" alt=\"Fig 1. Arquitectura de Transformers [3]\">\n",
    "    <p><em>Fig 1. Arquitectura de Transformers [3]</em></p>\n",
    "</div>\n",
    "\n",
    "Donde inicialmente nos interesa la etapa de encoding, donde las palabras son traducidas a un espacio vectorial dependiendo de su similitud semántica. Como se puede observar a continuación:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/Astolfo2332/white_paper_LoRa/main/images/3d_wordvec_3.png\" alt=\"Fig 2. Demostración de un embedings en un espacio 3D [5]\" width=\"50%\">\n",
    "    <p><em>Fig 2. Demostración de un embedings en un espacio 3D [5]</em></p>\n",
    "</div>\n",
    "\n",
    "De esta manera pudiendo operar matricialmente las palabras (en forma de vectores) con la arquitectura mostrada en la Fig 1.\n",
    "\n",
    "Anteriormente usando redes neuronales recurrentes (RNN) las cuales después de cada capa iban perdiendo la atención al texto ingresado debido a su naturaleza secuencial, donde en el entrenamiento se puede dar el fenómeno del desvanecimiento de gradientes, el cual implica que los gradientes a medida que pasan por la backpropagation se vuelven 0 o un valor cercano a este impidiendo al modelo aprender nueva información [3] además que la complejidad para volver a esa información requiere un tamaño menor $O(1)$ de Transformers comparado con el $O(n)$ de RNN [3]. Esto se soluciona mediante capas de atención las cuales son dadas por una serie de matrices a las cuales se les aplica una función softmax de la forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsEOI9UlnAv4"
   },
   "source": [
    "$$\n",
    "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYyhJIEdnAv4"
   },
   "source": [
    "Recordando que la función softmax  es [6]:\n",
    "\n",
    "$$\n",
    "\\text{softmax}(x_i) = \\frac{\\exp(x_i)}{\\sum_{j} \\exp(x_j)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXy59D84nAv5"
   },
   "outputs": [],
   "source": [
    "#Generación de embedings\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "\n",
    "\n",
    "text = [\"El gato es azul\", \"El perro es verde\", \"El cielo es azul\", \"El pasto es verde\"]\n",
    "\n",
    "\n",
    "def encode_text(text, tokenizer):\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    return tokenized_inputs[\"input_ids\"][0]\n",
    "\n",
    "inputs = [encode_text(t, tokenizer).numpy() for t in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxLSz9JbnAv5",
    "outputId": "4c8de20f-6d67-4ed2-99af-666c2f61ff94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  101,  3449, 11721,  3406,  9686, 17207,  5313,   102]),\n",
       " array([  101,  3449,  2566,  3217,  9686, 16184,   102,     0]),\n",
       " array([  101,  3449, 25022, 18349,  9686, 17207,  5313,   102]),\n",
       " array([  101,  3449,  2627,  2080,  9686, 16184,   102,     0])]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Encuentra la longitud máxima de las secuencias en 'inputs'\n",
    "max_length = max(len(seq) for seq in inputs)\n",
    "\n",
    "# Agrega padding de ceros a cada secuencia para que todas tengan la misma longitud\n",
    "padded_inputs = [np.pad(seq, (0, max_length - len(seq)), 'constant') for seq in inputs]\n",
    "\n",
    "padded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9gsHiaNnAv5",
    "outputId": "55cdec8f-0ac7-42cb-f21f-4cbd53effc5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capa de atención\n",
      " [[0.2517603  0.24117014 0.26620964 0.24085991]\n",
      " [0.25137197 0.24425888 0.26028139 0.24408776]\n",
      " [0.25219952 0.23427593 0.27991041 0.23361414]\n",
      " [0.25133767 0.24455666 0.25970371 0.24440196]]\n",
      "\n",
      "Salida de la atención\n",
      " [[0.30272187 0.37315351 0.24318054 0.17621523]\n",
      " [0.30153986 0.3715292  0.24174308 0.17500056]\n",
      " [0.30541302 0.37684938 0.24646852 0.17899182]\n",
      " [0.30142499 0.37137136 0.24160326 0.17488242]]\n"
     ]
    }
   ],
   "source": [
    "# Iniciando con numpy aunque este proceso se hace por medio de tensores\n",
    "L, d_v, d_k = len(padded_inputs[0]), 4, 4\n",
    "\n",
    "\n",
    "\n",
    "# Generamos valores aleatorios para Q, K, y V\n",
    "np.random.seed(23)  # Semilla para reproducibilidad\n",
    "\n",
    "Q = np.matmul(padded_inputs, np.random.rand(L, d_k) * 1e-5)\n",
    "V = np.matmul(padded_inputs, np.random.rand(L, d_v) * 1e-5)\n",
    "K = np.matmul(padded_inputs, np.random.rand(L, d_k) * 1e-5)\n",
    "\n",
    "\n",
    "\n",
    "# Calculamos la atención\n",
    "# QK^T\n",
    "QK_T = np.matmul(Q, K.T)\n",
    "\n",
    "# Dividimos por la raíz cuadrada de d_k\n",
    "QK_T_scaled = QK_T / np.sqrt(d_k)\n",
    "\n",
    "# Aplicamos la función softmax\n",
    "def softmax(x):\n",
    "    return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T\n",
    "\n",
    "attention_weights = softmax(QK_T_scaled)\n",
    "\n",
    "# Calculamos la salida de la atención\n",
    "output = np.matmul(attention_weights, V)\n",
    "\n",
    "\n",
    "print(\"Capa de atención\\n\", attention_weights)\n",
    "\n",
    "print(\"\\nSalida de la atención\\n\", output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ijq3UwTnAv5"
   },
   "source": [
    "En este ejemplo se usan 4 dimensiones, aunque en realidad la entrada de las matrices de atención son mayores. Por ejemplo, si quisiera reentrenar un modelo como GPT 3 el cual cuenta con 16.385 dimensiones [7] y 175 billones de parámetros [2], se incrementaria el gasto computacional para cada iteración. Por ende el uso de menos parámetros especializados para ajustar un modelo es necesario y una de estas soluciones es LoRa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_bgfI6TnAv5"
   },
   "source": [
    "## 3.LoRa [2]\n",
    "Este permite un ajuste eficiente, mediante la descomposición de bajo rango de las matrices de atención, obteniendo un mejor ajuste con pocos parámetros. Esto quiere decir que si se parte de el cómo funciona una LLM de forma general donde se tiene un  $W_0$ que corresponde las dimensiones de los pesos iniciales de un modelo entrenado , su ajuste esta dado por un $\\Delta W$ para que este dé una salida de predicción $h$ de la forma:\n",
    "$$\n",
    "h = W_0 x + \\Delta W x\n",
    "$$\n",
    "\n",
    "Supongase así que existe una descomposición para $\\Delta W$ donde $B \\in \\mathbb{R}^{d \\times r}$ y $A \\in \\mathbb{R}^{r \\times k}$, donde r es el rank y d las dimensiones de la matriz del modelo. Así si $\\nabla(W) x = BA x$ se tiene que:\n",
    "$$\n",
    "h = W_0 x + BA x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wy5O18KPnAv6"
   },
   "source": [
    "De una manera gráfica se puede expresar mediante la comparación de:\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/Astolfo2332/white_paper_LoRa/main/images/reaparam.png\" alt=\"Fig 3. Reparametrización en la que se basa LoRa [2]\" width=\"50%\">\n",
    "    <p><em>Fig 3. Reparametrización en la que se basa LoRa [2]</em></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTBlgdrGnAv6"
   },
   "source": [
    "Así los pesos de $A$ y $B$ son cambiados en el fine-tuning del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vgBHxVO4nAv6",
    "outputId": "ecea316f-3f36-47b2-8ac6-50fd7f0443e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor de h:\n",
      "[0.63938988 0.41702811 0.6272325  0.39643064]\n",
      "\n",
      "Ajuste de pesos normal:\n",
      "[[0.63938988 0.41702811 0.6272325  0.39643064]]\n",
      "\n",
      "Con una matriz delta_W:\n",
      "[[-0.06088618 -0.49694735 -0.44204427 -0.4775679 ]\n",
      " [-0.03393741 -0.27699402 -0.24639153 -0.26619208]\n",
      " [-0.00223585 -0.01824883 -0.01623269 -0.01753718]\n",
      " [-0.07928901 -0.64714951 -0.575652   -0.62191263]]\n",
      "\n",
      "Tamaños de W y A*B iguales: True\n",
      "\n",
      "Ajuste de pesos con A y B:\n",
      "[[0.63938988 0.41702811 0.6272325  0.39643064]]\n",
      "\n",
      "Con A:\n",
      "[[0.56478545 0.2982329  0.18519292 0.78085279]\n",
      " [0.15521475 0.60111895 0.73804002 0.5663141 ]]\n",
      "\n",
      "Con B:\n",
      "[[-0.35074381 -0.49795333]\n",
      " [-0.19550147 -0.27755474]\n",
      " [-0.01287996 -0.01828577]\n",
      " [-0.45675601 -0.64845955]]\n"
     ]
    }
   ],
   "source": [
    "#De una manera práctica se tiene:\n",
    "\n",
    "#Supongamos un valor h\n",
    "\n",
    "h = np.random.rand(d_k)\n",
    "\n",
    "#Donde los pesos iniciales son aleatorios\n",
    "W = np.random.rand(d_k, d_v)\n",
    "\n",
    "#Establecemos un X de entrada\n",
    "\n",
    "X = np.random.rand(d_k, 1)\n",
    "\n",
    "def normal_tuning(W, X, h):\n",
    "    #Calculamos el producto punto de W y X\n",
    "    WX = np.dot(W, X)\n",
    "    #Generamos la matriz delta_W en ceros\n",
    "    delta_W = np.zeros_like(W)\n",
    "    #Ajustamos los pesos de delta_W a base de h\n",
    "    for i in range(W.shape[0]):\n",
    "        delta_W[i], _, _, _ = np.linalg.lstsq(X.T, h[i] - WX[i], rcond=None)\n",
    "    return delta_W\n",
    "\n",
    "delta_W = normal_tuning(W, X, h)\n",
    "\n",
    "#Solución de h\n",
    "normal_h = np.dot(W, X) + np.dot(delta_W, X)\n",
    "\n",
    "print(\"Valor de h:\")\n",
    "print(h)\n",
    "\n",
    "print(\"\\nAjuste de pesos normal:\")\n",
    "print(normal_h.T)\n",
    "\n",
    "print(\"\\nCon una matriz delta_W:\")\n",
    "print(delta_W)\n",
    "\n",
    "#De la misma manera podemos ajustar los pesos de A y B, en este caso para ser prácticos solo ajustaremos\n",
    "#Los pesos de B al ser todos 0\n",
    "\n",
    "#Creamos la clase de LoRa\n",
    "class LoRa_tuning:\n",
    "    def __init__(self, A, h, W, X,r):\n",
    "        #Inicializamos las variables\n",
    "        self.A = A\n",
    "        self.h = h\n",
    "        self.W = W\n",
    "        self.X = X\n",
    "        self.B = np.zeros((W.shape[0], r))\n",
    "        self.d = W.shape[0]\n",
    "    def __call__(self):\n",
    "        #Calculamos los productos punto de A y X y W y X\n",
    "        Ax = np.dot(self.A, self.X)\n",
    "        Wx = np.dot(self.W, self.X)\n",
    "        #Ajustamos los pesos de B a base de h\n",
    "        for i in range(self.B.shape[0]):\n",
    "            self.B[i], _, _, _ = np.linalg.lstsq(Ax.T, h[i] - Wx[i], rcond=None)\n",
    "        return self.B\n",
    "    def solution(self):\n",
    "        # Calculamos la solución\n",
    "        return np.dot(self.W, self.X) + np.dot(np.dot(self.B, self.A), self.X)\n",
    "    def is_equal(self):\n",
    "        #Confirmamos que los tamaños de W y A*B sean iguales\n",
    "        return self.W.shape == np.dot(self.B, self.A).shape\n",
    "    def a_dot_b(self):\n",
    "        #Calculamos A*B\n",
    "        return np.dot(self.B, self.A)\n",
    "\n",
    "r = 2\n",
    "A = np.random.rand(r, d_k)\n",
    "\n",
    "\n",
    "LoRa = LoRa_tuning(A, h, W, X,r)\n",
    "B = LoRa()\n",
    "\n",
    "#Confirmamos que los tamaños de W y A*B sean iguales\n",
    "print(\"\\nTamaños de W y A*B iguales:\", LoRa.is_equal())\n",
    "\n",
    "print(\"\\nAjuste de pesos con A y B:\")\n",
    "print(LoRa.solution().T)\n",
    "\n",
    "print(\"\\nCon A:\")\n",
    "print(LoRa.A)\n",
    "\n",
    "print(\"\\nCon B:\")\n",
    "print(B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRCsW59nnAv6"
   },
   "source": [
    "Al final se obtiene el mismo resultado de ajuste, con menos parámetros que calcular en éste ejemplo, solo cambiando de pesos los 8 valores de la matriz $B$ a diferencia de los 16 del $\\Delta W$, reduciendo así la cantidad de parámetros a utilizar,correspondiente 2/3 de la VRAM necesaria para el entrenamiento, además de poder entrenar modelos más grandes como GPT-3 en menos GPU reduciendo la latencia entre estas, así como también el costo de computo y un aumento en la velocidad de entrenamiento en aproximadamente 25 % [2].\n",
    "\n",
    "Sin embargo, si se requieren hacer pruebas de concepto o encapsular modelos en microcontroladores o situaciones donde no se tenga tanta memoria para inferencia o entrenamiento, se requiere un paso extra tanto para su entrenamiento como su almacenamiento y una de estas soluciones es la cuantización.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRU_wsODnAv6"
   },
   "source": [
    "## 4. QLoRa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NocU0SV8nAv6"
   },
   "source": [
    "\n",
    "En este método se consta de dos partes, la primera ya conocida referente a cómo se puede aplicar LoRa y el porqué es útil para realizar el fine-tuning de LLMs, y ahora la cuantización. Esta técnica permite reducir los bits en los cuales se guardan los pesos de un modelo como se mencionó anteriormente en el caso de GPT 3 el cual contiene 175 billones de parámetros [2], los cuales están almacenados en pesos de flotante a 32 bits, ó también en la mayoría de LLM actuales de 16 bits.\n",
    "\n",
    "Sin embargo, un modelo de 65 billones de parámetros pasa de 780 GB a menos de 48 GB con una eficiencia similar al modelo entrenado completamente aplicando cuantización [4]. Esto se logró mediante la suposición de que los pesos de los modelos siguen una distribución normal, de esta forma se pueden segmentar todas las secciones de la curva en sectores más grandes o pequeños que tendrán una nueva representación de los parámetros. Dicho proceso puede ser revertido a la hora de inferencia,  además con el uso de un compaginador de memoria esta puede ser trasladada a la CPU para evitar el sobre flujo en la GPU como se puede observar a continuación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vp4z3W7hnAv6"
   },
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/Astolfo2332/white_paper_LoRa/main/images/quanti.png\" alt=\"Fig 4. Métodos de fine-tuning y QLoRa [4]\" width=\"60%\">\n",
    "    <p><em>Fig 4. Métodos de fine-tuning y QLoRa [4] </em></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3fDU7q-nAv6"
   },
   "source": [
    "Así, la cuantización se puede lograr por medio de bloques, en si la cuantización se logra por dos métodos 4 bit NormalFloat (NF4) y una doble cuantización. El final es “discretizar” la información como se puede observar a continuación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izflY-alnAv6"
   },
   "source": [
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/Astolfo2332/white_paper_LoRa/main/images/ex_cuanti.png\" alt=\"Fig 5. Ejemplo gráfico de como funciona la cuantización [8]\" width=\"60%\">\n",
    "    <p><em>Fig 5. Ejemplo gráfico de como funciona la cuantización [8]</em></p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpExqT61nAv7"
   },
   "source": [
    "Donde los sw son los quantiles a discretizar y, como se observa, la mayoría de datos discretizados se encuentran cercanos a la media de la distribución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CVN0_hQWnAv7"
   },
   "source": [
    "**NF4**: en este método se usan quantiles donde se agrupan valores de la distribución, dichos quantiles pueden codificar los datos del grupo de números que estén dentro de su conjunto, la principal dificultad es que no se tienen en cuenta los valores extremos de los pesos que en algunos casos son las partes más importantes en los modelos [4]. Para mitigar esto se pueden normalizar los pesos del modelo o escalarlos para una distribución en la que pueda funcionar el NF4, en rangos de -1 a 1, con una distribución estándar de $\\sigma$. Así se pueden obtener dos partes de una distribución normal, una positiva y negativa las cuales son representadas por un $2^{k-1}$ para la parte positiva y $2^{k-1}+1$. Para dicha estimación se usa la siguiente fórmula:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbXcmfEznAv7"
   },
   "source": [
    "$$\n",
    "q_i = \\frac{1}{2} \\left( Q_X\\left(\\frac{i}{2^k + 1}\\right) + Q_X\\left(\\frac{i+1}{2^k + 1}\\right) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rn8CuEvrnAv7"
   },
   "source": [
    "**Doble cuantización**: Como su nombre lo índica, es una cuantización doble. Esto trae ventajas en términos de memoria, ya que se reduce la huella dependiendo del bloque de memoria a usar, en el caso del paper se usan 64 para cada peso dando como resultando una constante de cuantización de $32 bits /64 = 0.5 bits$, y obteniendo así un peso de 8 bits, el cual pasa por otro proceso de cuantización, donde se tienen entonces $8 bits / 64 + 32 bits / (64 * 256)$ (del paso anterior) $= 0.127$.\n",
    "\n",
    "Estos dos métodos combinados con LoRa dependiendo del caso obtiene resultandos muy similares a un entrenamiento normal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T02:54:36.920948Z",
     "start_time": "2024-12-09T02:54:36.413264Z"
    },
    "id": "yFpX19AknAv7",
    "outputId": "894da991-91d4-4530-f42a-a7c41dcedddc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos originales extraídos:\n"
     ]
    }
   ],
   "source": [
    "#Para mostrar como se puede realizar este proceso se toma un modelo base\n",
    "\n",
    "import numpy as np\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import torch\n",
    "\n",
    "# Cargar el modelo y el tokenizador\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "model = DistilBertModel.from_pretrained(model_name)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Extraer los pesos originales del modelo\n",
    "original_weights = {}\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:  # Solo tomamos los pesos entrenables\n",
    "        original_weights[name] = param.detach().numpy()\n",
    "\n",
    "print(\"Pesos originales extraídos:\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T03:07:53.861054Z",
     "start_time": "2024-12-09T03:07:00.887188Z"
    },
    "id": "oJP-QZ3xnAv7",
    "outputId": "af0507b0-3726-477a-c976-84d99654215e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Graficamos uno de las capas de pesos para mostrar su distribución y es muy similar a la normal\n",
    "from scipy.stats import norm\n",
    "\n",
    "data = original_weights[\"transformer.layer.4.attention.q_lin.weight\"]\n",
    "\n",
    "mu, std = norm.fit(data)\n",
    "xmin = data.min()\n",
    "xmax = data.max()\n",
    "plt.xlim(xmin, xmax)\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "plt.hist(data, bins=100)\n",
    "plt.title(\"Distribución de pesos\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IyJRDUdtnAv7"
   },
   "source": [
    "Se puede apreciar que la distribución de los pesos es muy similar a una distribución normal, lo cual es un requisito para la cuantización de los pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T03:15:22.989697Z",
     "start_time": "2024-12-09T03:15:11.636451Z"
    },
    "id": "mULjowvMnAv7"
   },
   "outputs": [],
   "source": [
    "# Definir parámetros de la cuantización\n",
    "k = 4  # Cuantización en k bits\n",
    "num_levels = 2 ** k  # Niveles de cuantización\n",
    "block_size = 64  # Tamaño del bloque 64 como en el paper\n",
    "\n",
    "quantized_weights = {}\n",
    "scale_factors = {}\n",
    "\n",
    "for name, weight in original_weights.items():\n",
    "    shape = weight.shape\n",
    "    flat_weight = weight.flatten()\n",
    "    quantized = []\n",
    "    scales = []\n",
    "\n",
    "    # Dividir los pesos en bloques\n",
    "    for i in range(0, len(flat_weight), block_size):\n",
    "        block = flat_weight[i:i+block_size]\n",
    "\n",
    "        # Calcular rango y escala del bloque\n",
    "        min_val = block.min()\n",
    "        max_val = block.max()\n",
    "        scale = (max_val - min_val) / (num_levels - 1) if max_val > min_val else 1.0\n",
    "        zero_point = -min_val / scale\n",
    "\n",
    "        # Cuantizar el bloque\n",
    "        quant_block = ((block - min_val) / scale).clip(0, num_levels - 1).round().astype(np.uint8)\n",
    "\n",
    "        quantized.append(quant_block)\n",
    "        scales.append((min_val, scale, zero_point))\n",
    "\n",
    "    # Reconstruir la matriz cuantizada\n",
    "    quantized_weights[name] = (np.concatenate(quantized), scales)\n",
    "\n",
    "# Descuantización\n",
    "dequantized_weights = {}\n",
    "for name, (quantized, scales) in quantized_weights.items():\n",
    "    original_shape = original_weights[name].shape\n",
    "    dequantized_blocks = []\n",
    "\n",
    "    # Procesar cada bloque\n",
    "    block_start = 0\n",
    "    for min_val, scale, zero_point in scales:\n",
    "        block_end = block_start + block_size\n",
    "        quant_block = quantized[block_start:block_end]\n",
    "        block_start = block_end\n",
    "\n",
    "        # Descuantizar el bloque\n",
    "        dequant_block = quant_block * scale + min_val\n",
    "        dequantized_blocks.append(dequant_block)\n",
    "\n",
    "    # Reconstruir la matriz descuantizada\n",
    "    dequantized_weights[name] = np.concatenate(dequantized_blocks).reshape(original_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T03:22:06.540060Z",
     "start_time": "2024-12-09T03:21:10.230160Z"
    },
    "id": "DxoGvWEnnAv7",
    "outputId": "04d8c2ee-e69b-4170-a058-9a6b88c4caf3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#Graficamos uno de las capas de pesos para mostrar su distribución y es muy similar a la normal\n",
    "from scipy.stats import norm\n",
    "\n",
    "data = dequantized_weights[\"transformer.layer.4.attention.q_lin.weight\"]\n",
    "\n",
    "mu, std = norm.fit(data)\n",
    "xmin = data.min()\n",
    "xmax = data.max()\n",
    "plt.xlim(xmin, xmax)\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mu, std)\n",
    "\n",
    "plt.plot(x, p, 'k', linewidth=2)\n",
    "plt.hist(data, bins=100)\n",
    "plt.title(\"Distribución de pesos\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bp1aV1u3nAv7"
   },
   "source": [
    "Se obtuvo la misma gráfica de pesos mostrada anteriormente, solo que almacenada en 8 bits en vez de 32 bits. Así se puede realizar el proceso de cuantización y descuantización de los pesos de un modelo de LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TI5E8FYnnAv7"
   },
   "source": [
    "## 5. Caso práctico de uso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SnvoLeJnAv8"
   },
   "source": [
    "En mi trabajo final tuve que clasificar pregrados en clases para reducir la cantidad de información, esto se logro con un modelo especifico para esta tara conocidos como zero shoot clasification, que se encargan en a partir de una lista de palabras relacionar las de entrada. En este caso vamos a usar una parte de estos datos con un modelo que no esta diseñado para esta tarea.\n",
    "\n",
    "El código mostrado es una modificación de ShawhinT [8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maXSqm6rz7ZP"
   },
   "source": [
    "### Para amd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "niJGsAPKnAv8",
    "outputId": "7a50c6b2-d0cd-425e-8748-cf7e50a850c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/rocm6.2\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/rocm6.2/torch-2.5.1%2Brocm6.2-cp310-cp310-linux_x86_64.whl (3973.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 GB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/rocm6.2/torchvision-0.20.1%2Brocm6.2-cp310-cp310-linux_x86_64.whl (2.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/rocm6.2/torchaudio-2.5.1%2Brocm6.2-cp310-cp310-linux_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: jinja2 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "Collecting pytorch-triton-rocm==3.1.0 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/pytorch_triton_rocm-3.1.0-cp310-cp310-linux_x86_64.whl (344.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m344.8/344.8 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sympy==1.13.1 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Collecting numpy (from torchvision)\n",
      "  Downloading https://download.pytorch.org/whl/numpy-1.26.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading https://download.pytorch.org/whl/pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: mpmath, sympy, pillow, numpy, networkx, fsspec, filelock, pytorch-triton-rocm, torch, torchvision, torchaudio\n",
      "Successfully installed filelock-3.13.1 fsspec-2024.2.0 mpmath-1.3.0 networkx-3.2.1 numpy-1.26.3 pillow-10.2.0 pytorch-triton-rocm-3.1.0 sympy-1.13.1 torch-2.5.1+rocm6.2 torchaudio-2.5.1+rocm6.2 torchvision-0.20.1+rocm6.2\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Using cached transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "Using cached huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.26.5 regex-2024.11.6 safetensors-0.4.5 tokenizers-0.21.0 tqdm-4.67.1 transformers-4.47.0\n",
      "Collecting optimum\n",
      "  Using cached optimum-1.23.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting coloredlogs (from optimum)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: sympy in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from optimum) (1.13.1)\n",
      "Requirement already satisfied: transformers>=4.29 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from optimum) (4.47.0)\n",
      "Requirement already satisfied: torch>=1.11 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from optimum) (2.5.1+rocm6.2)\n",
      "Requirement already satisfied: packaging in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from optimum) (24.2)\n",
      "Requirement already satisfied: numpy in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from optimum) (1.26.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from optimum) (0.26.5)\n",
      "Collecting datasets (from optimum)\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2024.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.1.4)\n",
      "Requirement already satisfied: pytorch-triton-rocm==3.1.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch>=1.11->optimum) (3.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from sympy->optimum) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from transformers>=4.29->optimum) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from transformers>=4.29->optimum) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from transformers>=4.29->optimum) (0.4.5)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets->optimum)\n",
      "  Downloading pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->optimum)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets->optimum)\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting xxhash (from datasets->optimum)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->optimum)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting aiohttp (from datasets->optimum)\n",
      "  Downloading aiohttp-3.11.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets->optimum)\n",
      "  Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets->optimum)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets->optimum)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets->optimum)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->optimum)\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets->optimum)\n",
      "  Downloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets->optimum)\n",
      "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from jinja2->torch>=1.11->optimum) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets->optimum)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets->optimum)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.17.0)\n",
      "Using cached optimum-1.23.3-py3-none-any.whl (424 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading aiohttp-3.11.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading pyarrow-18.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Using cached aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Downloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, pyarrow, propcache, multidict, humanfriendly, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, coloredlogs, aiosignal, aiohttp, datasets, optimum\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.10 aiosignal-1.3.1 async-timeout-5.0.1 coloredlogs-15.0.1 datasets-3.2.0 dill-0.3.8 frozenlist-1.5.0 humanfriendly-10.0 multidict-6.1.0 multiprocess-0.70.16 optimum-1.23.3 pandas-2.2.3 propcache-0.2.1 pyarrow-18.1.0 pytz-2024.2 tzdata-2024.2 xxhash-3.5.0 yarl-1.18.3\n",
      "Collecting bitsandbytes==0.44.1.dev0\n",
      "  Downloading https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_multi-backend-refactor/bitsandbytes-0.44.1.dev0-py3-none-manylinux_2_24_x86_64.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from bitsandbytes==0.44.1.dev0) (2.5.1+rocm6.2)\n",
      "Requirement already satisfied: numpy in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from bitsandbytes==0.44.1.dev0) (1.26.3)\n",
      "Requirement already satisfied: filelock in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch->bitsandbytes==0.44.1.dev0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch->bitsandbytes==0.44.1.dev0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch->bitsandbytes==0.44.1.dev0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch->bitsandbytes==0.44.1.dev0) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch->bitsandbytes==0.44.1.dev0) (2024.2.0)\n",
      "Requirement already satisfied: pytorch-triton-rocm==3.1.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch->bitsandbytes==0.44.1.dev0) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch->bitsandbytes==0.44.1.dev0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from sympy==1.13.1->torch->bitsandbytes==0.44.1.dev0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes==0.44.1.dev0) (3.0.2)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.44.1.dev0+9315692\n",
      "Collecting auto-gptq\n",
      "  Downloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting accelerate>=0.26.0 (from auto-gptq)\n",
      "  Using cached accelerate-1.2.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: datasets in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from auto-gptq) (3.2.0)\n",
      "Collecting sentencepiece (from auto-gptq)\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: numpy in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from auto-gptq) (1.26.3)\n",
      "Collecting rouge (from auto-gptq)\n",
      "  Using cached rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting gekko (from auto-gptq)\n",
      "  Using cached gekko-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: torch>=1.13.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from auto-gptq) (2.5.1+rocm6.2)\n",
      "Requirement already satisfied: safetensors in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from auto-gptq) (0.4.5)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from auto-gptq) (4.47.0)\n",
      "Collecting peft>=0.5.0 (from auto-gptq)\n",
      "  Using cached peft-0.14.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: tqdm in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from auto-gptq) (4.67.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (24.2)\n",
      "Requirement already satisfied: psutil in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from accelerate>=0.26.0->auto-gptq) (0.26.5)\n",
      "Requirement already satisfied: filelock in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (2024.2.0)\n",
      "Requirement already satisfied: pytorch-triton-rocm==3.1.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from torch>=1.13.0->auto-gptq) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.13.0->auto-gptq) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from transformers>=4.31.0->auto-gptq) (0.21.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from datasets->auto-gptq) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from datasets->auto-gptq) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from datasets->auto-gptq) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from datasets->auto-gptq) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from datasets->auto-gptq) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from datasets->auto-gptq) (3.11.10)\n",
      "Requirement already satisfied: six in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from rouge->auto-gptq) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from aiohttp->datasets->auto-gptq) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from requests->transformers>=4.31.0->auto-gptq) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->auto-gptq) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages (from pandas->datasets->auto-gptq) (2024.2)\n",
      "Downloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached accelerate-1.2.0-py3-none-any.whl (336 kB)\n",
      "Using cached peft-0.14.0-py3-none-any.whl (374 kB)\n",
      "Using cached gekko-1.2.1-py3-none-any.whl (13.2 MB)\n",
      "Using cached rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece, rouge, gekko, accelerate, peft, auto-gptq\n",
      "Successfully installed accelerate-1.2.0 auto-gptq-0.7.1 gekko-1.2.1 peft-0.14.0 rouge-1.0.1 sentencepiece-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.2\n",
    "!pip install transformers\n",
    "!pip install optimum\n",
    "# Note, if you don't want to reinstall BNBs dependencies, append the `--no-deps` flag!\n",
    "!pip install 'https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_multi-backend-refactor/bitsandbytes-0.44.1.dev0-py3-none-manylinux_2_24_x86_64.whl'\n",
    "!pip install auto-gptq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmVEdOs_z-HY"
   },
   "source": [
    "### Para Nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BgRrU_-RnV-d",
    "outputId": "bf966232-6e94-40d8-a965-392e6d5e15e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optimum\n",
      "  Downloading optimum-1.23.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting coloredlogs (from optimum)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum) (1.13.1)\n",
      "Requirement already satisfied: transformers>=4.29 in /usr/local/lib/python3.10/dist-packages (from optimum) (4.46.3)\n",
      "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from optimum) (2.5.1+cu121)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from optimum) (24.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optimum) (1.26.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from optimum) (0.26.3)\n",
      "Collecting datasets (from optimum)\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (2024.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (6.0.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.29->optimum) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.29->optimum) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.29->optimum) (0.4.5)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (17.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->optimum)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (2.2.2)\n",
      "Collecting xxhash (from datasets->optimum)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->optimum)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.8.0->optimum)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (3.11.9)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.8.0->optimum) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->optimum) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n",
      "Downloading optimum-1.23.3-py3-none-any.whl (424 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.1/424.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, humanfriendly, fsspec, dill, multiprocess, coloredlogs, datasets, optimum\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.10.0\n",
      "    Uninstalling fsspec-2024.10.0:\n",
      "      Successfully uninstalled fsspec-2024.10.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed coloredlogs-15.0.1 datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 humanfriendly-10.0 multiprocess-0.70.16 optimum-1.23.3 xxhash-3.5.0\n",
      "Collecting auto-gptq\n",
      "  Downloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.1.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (3.2.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.2.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.26.4)\n",
      "Collecting rouge (from auto-gptq)\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting gekko (from auto-gptq)\n",
      "  Downloading gekko-1.2.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (2.5.1+cu121)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.4.5)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.46.3)\n",
      "Requirement already satisfied: peft>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.13.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.66.6)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto-gptq) (0.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto-gptq) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto-gptq) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.26.0->auto-gptq) (6.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->auto-gptq) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->auto-gptq) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->auto-gptq) (0.20.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->auto-gptq) (3.11.9)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->auto-gptq) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->auto-gptq) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->auto-gptq) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->auto-gptq) (2024.2)\n",
      "Downloading auto_gptq-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gekko-1.2.1-py3-none-any.whl (13.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge, gekko, auto-gptq\n",
      "Successfully installed auto-gptq-0.7.1 gekko-1.2.1 rouge-1.0.1\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
      "Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optimum\n",
    "!pip install auto-gptq\n",
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:21:50.574539Z",
     "start_time": "2024-12-10T21:21:48.133688Z"
    },
    "id": "XkYrrg_knAv8"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import prepare_model_for_kbit_training\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:21:51.055872Z",
     "start_time": "2024-12-10T21:21:50.591164Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "F0wiTk11nAv8",
    "outputId": "f39a5fb9-6cd8-4963-aa7f-a72f40ebcad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LovyQaGX0Epp"
   },
   "source": [
    "Primero cargamos un modelo previamente cuantizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:21:54.839432Z",
     "start_time": "2024-12-10T21:21:51.166310Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390,
     "referenced_widgets": [
      "249e64cfd9134144bbff1b580c0db46b",
      "300c2b0ec6e64bdeb32e4c3f46eae6a2",
      "7e40c71123bf4352bd7608dcd71a177b",
      "abe0b71b6c2f45c692c848241c619f51",
      "a6131f5372284c3ab190b4b2acee0dd5",
      "dea72b99a81944caa7f9d320bb94017d",
      "5edcfea1779f4779826d31fc541c5672",
      "9e3f8deae1204b6eb24d315c80fb97bc",
      "67b4d30755554a02a626e42595eb88dc",
      "11824195da674d4b9172a15f74173db0",
      "fa196e755e0e4877bb4d571d0c9523bb",
      "0aa615ab2392473b8fe36de7ca8a2886",
      "6ea80e7fb6234594a10d9524c9eb1363",
      "e34b1e50f94342d698bab8ca04c1f1d1",
      "ec2e4951c55b4b44b21890e115724984",
      "f4fcab9f948a40e082f5a11cf8a4f4ee",
      "5f9983b2333841d0ad889df6b3db54b2",
      "599d99ba1f2c4c7f948e822fbcf16eee",
      "62571077099d4ff09411dd35016717d9",
      "970dce35ee0d41e8b5c3bf7f70b30e91",
      "8988edcc5c5342e6a245cbe42ae6d849",
      "79312d6fc23947efb9f44ca599af10a0",
      "02a8783a70c24c428f87e4863fa76de1",
      "1cd395c812c94ce9945ae4c39c49ad5c",
      "3f0a515d1a294247b270906b3b3018d9",
      "f389dd6ea160482e91e6f8fa4214ec31",
      "341a7e85c70046baac22ace0d1ed4d0b",
      "6510685f788e476fa25a129e5f70aab3",
      "039c1df315ef4b168693135ae2c61258",
      "11d9577c55cc4cfeb04481c14b50be98",
      "e3e02036fded4e4d97a658af0d2ca8cd",
      "0d080370f5984bb28fce48bb297e2dcd",
      "6a6a15c9ad97426f802dda56edf0b033"
     ]
    },
    "id": "dh0QKBHWnAv_",
    "outputId": "e14e03be-87e6-41a5-8d73-b3fc7301a89b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/auto_gptq/nn_modules/triton_utils/kernels.py:411: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, input, qweight, scales, qzeros, g_idx, bits, maxq):\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/auto_gptq/nn_modules/triton_utils/kernels.py:419: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/auto_gptq/nn_modules/triton_utils/kernels.py:461: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd(cast_inputs=torch.float16)\n",
      "CUDA extension not installed.\n",
      "CUDA extension not installed.\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/transformers/modeling_utils.py:5055: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
      "Some weights of the model checkpoint at TheBloke/CapybaraHermes-2.5-Mistral-7B-GPTQ were not used when initializing MistralForCausalLM: ['model.layers.0.mlp.down_proj.bias', 'model.layers.0.mlp.gate_proj.bias', 'model.layers.0.mlp.up_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.0.self_attn.o_proj.bias', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.1.mlp.down_proj.bias', 'model.layers.1.mlp.gate_proj.bias', 'model.layers.1.mlp.up_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.1.self_attn.o_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.10.mlp.down_proj.bias', 'model.layers.10.mlp.gate_proj.bias', 'model.layers.10.mlp.up_proj.bias', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.10.self_attn.o_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.11.mlp.down_proj.bias', 'model.layers.11.mlp.gate_proj.bias', 'model.layers.11.mlp.up_proj.bias', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.11.self_attn.o_proj.bias', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.12.mlp.down_proj.bias', 'model.layers.12.mlp.gate_proj.bias', 'model.layers.12.mlp.up_proj.bias', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.o_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.13.mlp.down_proj.bias', 'model.layers.13.mlp.gate_proj.bias', 'model.layers.13.mlp.up_proj.bias', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.13.self_attn.o_proj.bias', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.14.mlp.down_proj.bias', 'model.layers.14.mlp.gate_proj.bias', 'model.layers.14.mlp.up_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.14.self_attn.o_proj.bias', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.15.mlp.down_proj.bias', 'model.layers.15.mlp.gate_proj.bias', 'model.layers.15.mlp.up_proj.bias', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.15.self_attn.o_proj.bias', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.16.mlp.down_proj.bias', 'model.layers.16.mlp.gate_proj.bias', 'model.layers.16.mlp.up_proj.bias', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.16.self_attn.o_proj.bias', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.17.mlp.down_proj.bias', 'model.layers.17.mlp.gate_proj.bias', 'model.layers.17.mlp.up_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.17.self_attn.o_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.18.mlp.down_proj.bias', 'model.layers.18.mlp.gate_proj.bias', 'model.layers.18.mlp.up_proj.bias', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.18.self_attn.o_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.19.mlp.down_proj.bias', 'model.layers.19.mlp.gate_proj.bias', 'model.layers.19.mlp.up_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.19.self_attn.o_proj.bias', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.2.mlp.down_proj.bias', 'model.layers.2.mlp.gate_proj.bias', 'model.layers.2.mlp.up_proj.bias', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.2.self_attn.o_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.20.mlp.down_proj.bias', 'model.layers.20.mlp.gate_proj.bias', 'model.layers.20.mlp.up_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.20.self_attn.o_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.21.mlp.down_proj.bias', 'model.layers.21.mlp.gate_proj.bias', 'model.layers.21.mlp.up_proj.bias', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.21.self_attn.o_proj.bias', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.22.mlp.down_proj.bias', 'model.layers.22.mlp.gate_proj.bias', 'model.layers.22.mlp.up_proj.bias', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.22.self_attn.o_proj.bias', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.23.mlp.down_proj.bias', 'model.layers.23.mlp.gate_proj.bias', 'model.layers.23.mlp.up_proj.bias', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.23.self_attn.o_proj.bias', 'model.layers.23.self_attn.q_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.24.mlp.down_proj.bias', 'model.layers.24.mlp.gate_proj.bias', 'model.layers.24.mlp.up_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.24.self_attn.o_proj.bias', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.25.mlp.down_proj.bias', 'model.layers.25.mlp.gate_proj.bias', 'model.layers.25.mlp.up_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.25.self_attn.o_proj.bias', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.26.mlp.down_proj.bias', 'model.layers.26.mlp.gate_proj.bias', 'model.layers.26.mlp.up_proj.bias', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.26.self_attn.o_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.27.mlp.down_proj.bias', 'model.layers.27.mlp.gate_proj.bias', 'model.layers.27.mlp.up_proj.bias', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.27.self_attn.o_proj.bias', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.28.mlp.down_proj.bias', 'model.layers.28.mlp.gate_proj.bias', 'model.layers.28.mlp.up_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.28.self_attn.o_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.29.mlp.down_proj.bias', 'model.layers.29.mlp.gate_proj.bias', 'model.layers.29.mlp.up_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.29.self_attn.o_proj.bias', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.3.mlp.down_proj.bias', 'model.layers.3.mlp.gate_proj.bias', 'model.layers.3.mlp.up_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.3.self_attn.o_proj.bias', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.30.mlp.down_proj.bias', 'model.layers.30.mlp.gate_proj.bias', 'model.layers.30.mlp.up_proj.bias', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.30.self_attn.o_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.31.mlp.down_proj.bias', 'model.layers.31.mlp.gate_proj.bias', 'model.layers.31.mlp.up_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.31.self_attn.o_proj.bias', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.4.mlp.down_proj.bias', 'model.layers.4.mlp.gate_proj.bias', 'model.layers.4.mlp.up_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.4.self_attn.o_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.5.mlp.down_proj.bias', 'model.layers.5.mlp.gate_proj.bias', 'model.layers.5.mlp.up_proj.bias', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.5.self_attn.o_proj.bias', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.6.mlp.down_proj.bias', 'model.layers.6.mlp.gate_proj.bias', 'model.layers.6.mlp.up_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.6.self_attn.o_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.7.mlp.down_proj.bias', 'model.layers.7.mlp.gate_proj.bias', 'model.layers.7.mlp.up_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.7.self_attn.o_proj.bias', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.8.mlp.down_proj.bias', 'model.layers.8.mlp.gate_proj.bias', 'model.layers.8.mlp.up_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.8.self_attn.o_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.9.mlp.down_proj.bias', 'model.layers.9.mlp.gate_proj.bias', 'model.layers.9.mlp.up_proj.bias', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.9.self_attn.o_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.9.self_attn.v_proj.bias']\n",
      "- This IS expected if you are initializing MistralForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MistralForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"TheBloke/CapybaraHermes-2.5-Mistral-7B-GPTQ\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                            device_map=\"auto\",\n",
    "                                             trust_remote_code=False,\n",
    "                                             revision=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-caxJTItnAv_"
   },
   "source": [
    "Se inicia el tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:21:55.156714Z",
     "start_time": "2024-12-10T21:21:54.850562Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "b94b60ec5fdd4f9f8ecc0baaed6bd1b4",
      "e3d4ea757d844f09a81751a96ec9dc35",
      "da2cfc62f4d045dc8767d46ace81fa38",
      "889dc00d38414e58bb833d9670a6db6c",
      "b077340d90c640048426ab1eea849fcc",
      "c27e604baacd4e0eb600b41be40dc40e",
      "69daa293a3ef49c6b84f428101bb812a",
      "9bcd2145e0734418b0a481276904e303",
      "2c368d3d73ba4868b9eb0f81c9177d31",
      "e0564fcb36374c36b156899559c84fb5",
      "8f11202ce6014764be95c37a48aa3b23",
      "24523c635e44406889f397e7cabdf77d",
      "92a05c1ae0b34dd3b24e6e0f1b9739cb",
      "2f710924d984463db963b2e66cb6c732",
      "4e184f021fc04398bbd88fd54242463b",
      "32116f9b72254e119da39c12804c94b3",
      "0a7297698ae545dd8669fa6471df1275",
      "5d3110ff623145869b65a8eb46e2aa9a",
      "1a13144c57904ca387d2c2077a0281e9",
      "434bc22c1be14c5e9072116bf0a70baa",
      "0b3af3cbdde047beb92892986f3b957b",
      "89588702a550497f8c1d7989ddf69132",
      "6b0f0c96ddf24e1886ffe61c1e1657c7",
      "830d794b6fd14d35a96f801582c4d48b",
      "5ab2344195c94b61a46d38acd0a2ed2d",
      "0d35c45251094774b14e4de881e1d963",
      "a21242f9cf624306ae579ba5661ba8de",
      "ebf03e06d9c94441ad15a86ad09d5d6f",
      "ab23f1a7e5ac4cb791d13bc66377f67f",
      "15383431173b4b9797e2bbe6bccca21e",
      "f91d683a3a9047ea82662a2f29cffafd",
      "ec9ae05696cd443c8cc924b7143496fe",
      "e365331202694cb8a93388e71d40e743",
      "6c0947f7c1a5478382054d8960e6f550",
      "d94d662dbbd543a1831918df97db549c",
      "da5e8305f5ed447cade033cc9de0594e",
      "07a8f85d57ea4a62ba8c706388f27202",
      "0bd59d6bbeb54ff595ff0ae16568b426",
      "ee4ac058e10c4edb85efff6d0ac45b7a",
      "9504c76de3764aa68ab04202131770ba",
      "0655fdec80604cc6adfb0c9ade9a295d",
      "b380646d0a9f4b43be488bb18d7b10d9",
      "e3944fe6ef3c4b20b13770a2b265605d",
      "cbda611225044d71b97fd8f1e29668a8",
      "649f1c4765a948cfb0c607ebee23373e",
      "f71fbfda1a3b4b43914c5678a372c8bc",
      "6f58f7a4b76841d99021f5097f849a82",
      "819c01f304234e65b6451bd1a70df392",
      "64d3a42260464901831a950f61b1aa06",
      "b7f1a9116bd941db85d4be66ea5f51fc",
      "6f97fdc36f08437fa5cfc1c6337dd902",
      "b7a7391e63b5484884146918f13e3f0d",
      "013f84048f9c487a8c7df42e0b234d6a",
      "5a9a5b68d85e47a19b370fe94812afc6",
      "69dbae2e26cd4594a8e5a4c07ca0c4db"
     ]
    },
    "id": "ypK8hQs8nAv_",
    "outputId": "63787da5-676a-4c06-e395-475cb17b1a6c"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFLuQDeVnAv_"
   },
   "source": [
    "Configuramos LoRa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mh0fBnGY0Iz5"
   },
   "source": [
    "En este caso lo configuramos como un casual LM, para así mantener su uso general y que sea funcional para nuestra tarea en especifico que sería clasificar texto. recordando el r del ranking de LoRa y su $\\alpha$ para la delimitación de matrices y en que capa (target_modules) vamos a aplicar el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:21:55.911962Z",
     "start_time": "2024-12-10T21:21:55.165467Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_poBQiNqnAwA",
    "outputId": "a8039518-d644-4b6d-bdd9-ad5d9526e1dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g++ (GCC) 14.2.1 20240910\n",
      "Copyright (C) 2024 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "trainable params: 2,097,152 || all params: 264,523,776 || trainable%: 0.7928\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "config = LoraConfig(\n",
    "  r=8,\n",
    "  lora_alpha=32,\n",
    "  target_modules=[\"q_proj\"],\n",
    "  lora_dropout=0.5,\n",
    "  bias=\"none\",\n",
    "  task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ne4jWzYVnAwA"
   },
   "source": [
    "Organizamos el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:21:58.080051Z",
     "start_time": "2024-12-10T21:21:58.077280Z"
    },
    "id": "xAgT2WKZnAwA"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data/class_labels.json\", \"r\") as f:\n",
    "    class_labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:21:59.438642Z",
     "start_time": "2024-12-10T21:21:59.436259Z"
    },
    "id": "68fxv889nAwA"
   },
   "outputs": [],
   "source": [
    "categories = list(set(class_labels.values()))\n",
    "\n",
    "prompt = f\"\"\"<|im_start|>system\n",
    "Eres un modelo de lenguaje que va a clasificar textos en diferentes categorías.\n",
    "\"\"\" + str(categories) + \"\"\" ¿cuál de es la más adecuada para el siguiente texto?:<|im_end|>\n",
    "<|im_start|>user\n",
    "{prompt}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{response}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:22:01.219395Z",
     "start_time": "2024-12-10T21:22:01.209781Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6nSlx-ZUnAwA",
    "outputId": "5ba7a45d-2783-4dab-f218-41d5adfdba78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['example'],\n",
      "        num_rows: 150\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['example'],\n",
      "        num_rows: 150\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from datasets import Dataset, DatasetDict\n",
    "indices = random.sample(range(len(class_labels)), 150)\n",
    "data = {\"example\": [prompt.format(prompt=text, response=category) for text, category in class_labels.items()]}\n",
    "data_train = {\"example\": [data[\"example\"][i] for i in indices]}\n",
    "\n",
    "indices = random.sample(range(len(class_labels)), 150)\n",
    "data_test = {\"example\": [data[\"example\"][i] for i in indices]}\n",
    "\n",
    "dataset = Dataset.from_dict(data_train)\n",
    "dataset_test = Dataset.from_dict(data_test)\n",
    "\n",
    "\n",
    "dataset_dict = DatasetDict({\"train\": dataset, \"test\": dataset_test})\n",
    "\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:22:03.070042Z",
     "start_time": "2024-12-10T21:22:03.010366Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "68c679fd160641d09284d156871e3f3c",
      "6e5cc4e6437d4080bef63a8eb5ade8e7",
      "2a2f4f942e264de99073ad7cfc1f758e",
      "1655d6907d3542a2ab7129941d3976fa",
      "f9cbfb4c72c045e1adc3ca77a2d473e3",
      "3b37687480b44dddafa47ecafd2f51c2",
      "b225d860d5b641d186c89192087e1cee",
      "7714416309834b5087e36eee3304f862",
      "f5ebe14ab49e4d02a047cffbb81afc8e",
      "7eb23830ac7e4fe386de88d1df580b94",
      "1e033afb0e51426f9e980cfe99fd46b4",
      "4bbc07a4c2fd4f56a74b590f136e9d5d",
      "54928ac8fd8a435eb30587d9d97c2d81",
      "f971f33d3d47413698152685393f4e63",
      "49ac19654898427c852d236f63091478",
      "97237fb5eec2464ca7a5034403da18eb",
      "2da8416f089340fd8d56abe10cc34dea",
      "fd5a98813da347af814a016259165f58",
      "3b3a8de6ee284fdba4abe87f32d961bc",
      "2018951f6ed34430bea95ec9c7943e70",
      "b8e6ca89ecc84a73871f4edd894c16bf",
      "3586f30e07bd4db48c17e9da2e396f99"
     ]
    },
    "id": "0a2NJ_XHnAwA",
    "outputId": "fac9262a-d2b3-46a9-cdff-7991a9d1bfb1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8889aa920d2a47dfa8517fce9e5bd3d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59c562264b3466c9f7346dd712df0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenizer_func(example: dict):\n",
    "    text = example[\"example\"]\n",
    "\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text, #Se pasa el texto\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True, #En el caso que no cumpla con 512 se llena de tokens vacios\n",
    "        max_length=512 #Se ajusta a 512 debido a que es el tamaño del modelo\n",
    "    )\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_data = dataset_dict.map(tokenizer_func, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:22:05.251818Z",
     "start_time": "2024-12-10T21:22:05.244658Z"
    },
    "id": "kqhUvQCGnAwB"
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:22:07.767187Z",
     "start_time": "2024-12-10T21:22:07.750621Z"
    },
    "id": "grwwwKxlnAwB"
   },
   "outputs": [],
   "source": [
    "lr = 2e-4\n",
    "batch_size = 4\n",
    "num_epochs = 30\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir= \"../models/\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=2,\n",
    "    fp16=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T21:47:56.356597Z",
     "start_time": "2024-12-10T21:22:14.233495Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 732
    },
    "id": "sxgOjG_dnAwB",
    "outputId": "61f3b99d-73c8-46d2-9ab9-c80c3e78df21"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/auto_gptq/nn_modules/qlinear/qlinear_cuda.py:313: UserWarning: Attempting to use hipBLASLt on an unsupported architecture! Overriding blas backend to hipblas (Triggered internally at ../aten/src/ATen/Context.cpp:296.)\n",
      "  out = torch.matmul(x, weights)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:456: UserWarning: Memory Efficient attention on Navi31 GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:269.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [270/270 25:37, Epoch 27/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.664400</td>\n",
       "      <td>1.373475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.814900</td>\n",
       "      <td>0.421645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.340400</td>\n",
       "      <td>0.311942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.277000</td>\n",
       "      <td>0.281766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.248700</td>\n",
       "      <td>0.271533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.232600</td>\n",
       "      <td>0.264863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.267920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.213900</td>\n",
       "      <td>0.263998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.205500</td>\n",
       "      <td>0.264662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.199700</td>\n",
       "      <td>0.268372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.196700</td>\n",
       "      <td>0.269133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.194700</td>\n",
       "      <td>0.266181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.271596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.189700</td>\n",
       "      <td>0.277728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.270145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.279747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.185600</td>\n",
       "      <td>0.277229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.185300</td>\n",
       "      <td>0.280209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.184800</td>\n",
       "      <td>0.279342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.182600</td>\n",
       "      <td>0.280842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.183100</td>\n",
       "      <td>0.279890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.181600</td>\n",
       "      <td>0.280864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.181700</td>\n",
       "      <td>0.283708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.181300</td>\n",
       "      <td>0.286150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.284696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>0.285661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.179400</td>\n",
       "      <td>0.286508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:456: UserWarning: Flash attention support on Navi31 GPU is still experimental. Enable it with TORCH_ROCM_AOTRITON_ENABLE_EXPERIMENTAL=1. (Triggered internally at ../aten/src/ATen/native/transformers/hip/sdp_utils.cpp:225.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/kaiki/anaconda3/envs/transformers/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Se configura el entrenador\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"test\"],\n",
    "    args=training_args,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# Se entrena el modelo\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()\n",
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czwXb_xd0ohJ"
   },
   "source": [
    "Probamos los resultados del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T22:19:09.028162Z",
     "start_time": "2024-12-10T22:19:09.021692Z"
    },
    "id": "euO1bXvg0oRp"
   },
   "outputs": [],
   "source": [
    "\n",
    "data = {\"example\": [prompt.format(prompt=text, response=\"\") for text, _ in class_labels.items()]}\n",
    "resp = {\"resp\": [category for category in class_labels.values()]}\n",
    "\n",
    "indices = random.sample(range(len(class_labels)), 50)\n",
    "data_test =  [data[\"example\"][i] for i in indices]\n",
    "data_resp = [resp[\"resp\"][i] for i in indices]\n",
    "inputs = tokenizer(data_test, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T22:20:06.019316Z",
     "start_time": "2024-12-10T22:19:25.896226Z"
    },
    "id": "IYW-U4em4GuB"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    model_output = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"].to(device),\n",
    "        attention_mask=inputs[\"attention_mask\"].to(device),\n",
    "        max_new_tokens=100,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "generated_text = tokenizer.batch_decode(model_output, skip_special_tokens=True)\n",
    "\n",
    "model_responses = generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T22:56:16.302995Z",
     "start_time": "2024-12-10T22:56:16.296665Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "vSQwBhLF_OYm",
    "outputId": "52c34830-db2c-4f6c-d75b-c848135066d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_response</th>\n",
       "      <th>resp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>humanidades</td>\n",
       "      <td>humanidades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>educación</td>\n",
       "      <td>ciencias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ingeniería</td>\n",
       "      <td>ingeniería</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>humanidades</td>\n",
       "      <td>humanidades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>derecho</td>\n",
       "      <td>derecho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>educación</td>\n",
       "      <td>educación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>educación</td>\n",
       "      <td>educación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>salud</td>\n",
       "      <td>salud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>humanidades</td>\n",
       "      <td>humanidades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>humanidades</td>\n",
       "      <td>investigación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>educación</td>\n",
       "      <td>educación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>salud</td>\n",
       "      <td>humanidades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ingeniería</td>\n",
       "      <td>ingeniería</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>salud</td>\n",
       "      <td>salud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>investigación</td>\n",
       "      <td>investigación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>humanidades</td>\n",
       "      <td>humanidades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>educación</td>\n",
       "      <td>educación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>humanidades</td>\n",
       "      <td>arte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>administración</td>\n",
       "      <td>administración</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ciencias</td>\n",
       "      <td>ciencias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>educación</td>\n",
       "      <td>educación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ingeniería</td>\n",
       "      <td>ingeniería</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>investigación</td>\n",
       "      <td>investigación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>humanidades</td>\n",
       "      <td>arte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>arte</td>\n",
       "      <td>arte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>educación</td>\n",
       "      <td>educación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ingeniería</td>\n",
       "      <td>ingeniería</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ingeniería</td>\n",
       "      <td>ingeniería</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>humanidades</td>\n",
       "      <td>humanidades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ciencias</td>\n",
       "      <td>economía</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>educación</td>\n",
       "      <td>educación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>administración</td>\n",
       "      <td>administración</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>educación</td>\n",
       "      <td>educación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ciencias</td>\n",
       "      <td>ciencias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ingeniería</td>\n",
       "      <td>ingeniería</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ingeniería</td>\n",
       "      <td>ingeniería</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ingeniería</td>\n",
       "      <td>ingeniería</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>educación</td>\n",
       "      <td>educación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>humanidades</td>\n",
       "      <td>humanidades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>arte</td>\n",
       "      <td>arte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>humanidades</td>\n",
       "      <td>humanidades</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>arte</td>\n",
       "      <td>arte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ingeniería</td>\n",
       "      <td>ingeniería</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>educación</td>\n",
       "      <td>educación</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ciencias</td>\n",
       "      <td>ciencias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ingeniería</td>\n",
       "      <td>ingeniería</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>humanidades</td>\n",
       "      <td>arte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>administración</td>\n",
       "      <td>administración</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ingeniería</td>\n",
       "      <td>ingeniería</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ingeniería</td>\n",
       "      <td>ingeniería</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model_response            resp\n",
       "0      humanidades     humanidades\n",
       "1        educación        ciencias\n",
       "2       ingeniería      ingeniería\n",
       "3      humanidades     humanidades\n",
       "4          derecho         derecho\n",
       "5        educación       educación\n",
       "6        educación       educación\n",
       "7            salud           salud\n",
       "8      humanidades     humanidades\n",
       "9      humanidades   investigación\n",
       "10       educación       educación\n",
       "11           salud     humanidades\n",
       "12      ingeniería      ingeniería\n",
       "13           salud           salud\n",
       "14   investigación   investigación\n",
       "15     humanidades     humanidades\n",
       "16       educación       educación\n",
       "17     humanidades            arte\n",
       "18  administración  administración\n",
       "19        ciencias        ciencias\n",
       "20       educación       educación\n",
       "21      ingeniería      ingeniería\n",
       "22   investigación   investigación\n",
       "23     humanidades            arte\n",
       "24            arte            arte\n",
       "25       educación       educación\n",
       "26      ingeniería      ingeniería\n",
       "27      ingeniería      ingeniería\n",
       "28     humanidades     humanidades\n",
       "29        ciencias        economía\n",
       "30       educación       educación\n",
       "31  administración  administración\n",
       "32       educación       educación\n",
       "33        ciencias        ciencias\n",
       "34      ingeniería      ingeniería\n",
       "35      ingeniería      ingeniería\n",
       "36      ingeniería      ingeniería\n",
       "37       educación       educación\n",
       "38     humanidades     humanidades\n",
       "39            arte            arte\n",
       "40     humanidades     humanidades\n",
       "41            arte            arte\n",
       "42      ingeniería      ingeniería\n",
       "43       educación       educación\n",
       "44        ciencias        ciencias\n",
       "45      ingeniería      ingeniería\n",
       "46     humanidades            arte\n",
       "47  administración  administración\n",
       "48      ingeniería      ingeniería\n",
       "49      ingeniería      ingeniería"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def repeats(string):\n",
    "    #(regex no funcionó)\n",
    "    for x in range(1, len(string)):\n",
    "        #Vamos tomando el string desde atrás\n",
    "        substring = string[:x]\n",
    "        #Así si multiplicamos dicho valor por 2 y es igual al string significa que se repite\n",
    "        if substring * 2 == string:\n",
    "            return substring\n",
    "    return string\n",
    "\n",
    "#Se limpia la información de la respuesta del modelo\n",
    "model_responses_2 = [response.split(\"assistant\")[1].replace(\"\\n\",\"\").split(\" \")[0] for response in model_responses]\n",
    "#Eliminamos las palabras que se duplican ejm:educacióneducación\n",
    "model_responses_2 =  [repeats(response) for response in model_responses_2]\n",
    "df = pd.DataFrame({\"model_response\": model_responses_2, \"resp\": data_resp})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T22:56:18.531572Z",
     "start_time": "2024-12-10T22:56:18.528497Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.0 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#Se calcula la precisión del modelo\n",
    "\n",
    "accuracy = accuracy_score(df[\"resp\"], df[\"model_response\"])\n",
    "\n",
    "print(f\"Accuracy: {accuracy * 100} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ccj9fDsDeFd"
   },
   "source": [
    "Así mostrando lo util que puede ser el entrenamiento e inferencia de un modelo grande cuantizado, en este caso el modelo en su etapa de entrenamiento e inferencia solo ocupó 5.2 GB de VRAM.\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/Astolfo2332/white_paper_LoRa/main/images/vram.png\" alt=\"Fig 6. VRAM usada para el entrenamiento e inferencia del modelo\" width=\"60%\">\n",
    "    <p><em>Fig 6. VRAM usada para el entrenamiento e inferencia del modelo</em></p>\n",
    "</div>\n",
    "\n",
    "Además de aun contar con sus capacidades generales de respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T22:15:21.695107Z",
     "start_time": "2024-12-10T22:14:33.738931Z"
    },
    "id": "rtl2EkIjDZWF"
   },
   "outputs": [],
   "source": [
    "prompt_2 = \"\"\"<|im_start|>system\n",
    "Eres un asistente de cocina especializado en dulces. responde a la siguiente pregunta:<|im_end|>\n",
    "<|im_start|>user\n",
    "Como puedo hacer un pastel de zanahoria?<|im_end|>\n",
    "<|im_start|>assistant\"\"\"\n",
    "\n",
    "inputs_test = tokenizer(prompt_2, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    model_output = model.generate(\n",
    "        input_ids=inputs_test[\"input_ids\"],\n",
    "        attention_mask=inputs_test[\"attention_mask\"],\n",
    "        max_new_tokens=150,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T22:16:39.053944Z",
     "start_time": "2024-12-10T22:16:39.051371Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "E96aGZSgE9O2",
    "outputId": "6daf66a2-70fd-4d1d-9a1d-3487adac22d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Para hacer un delicioso pastel de zanahoria, sigue estos pasos:\n",
      "\n",
      "**Ingredientes:**\n",
      "\n",
      "Para el pastel:\n",
      "\n",
      "* 250 g de harina de pan\n",
      "* 1/2 taza de mantequilla\n",
      "* 1/2 taza de azúcar\n",
      "* 1 huevo\n",
      "* 1/2 taza de azúcar moreno\n",
      "* 1/2 taza de harina de soja\n",
      "* 1/2 taza de fécula de maní\n",
      "* 1/2 taza de leche de almendras\n",
      "* 1 taza\n"
     ]
    }
   ],
   "source": [
    "generated_text = tokenizer.batch_decode(model_output, skip_special_tokens=True)\n",
    "print(generated_text[0].split(\"assistant\")[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mz39XqvDHC_I"
   },
   "source": [
    "## 6. Conclusiones\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En conclusión, se destaca la importancia y versatilidad de la cuantización en las LLMs, una técnica que optimiza el uso de recursos computacionales al reducir la precisión de los parámetros del modelo, permitiendo su implementación en dispositivos con recursos limitados sin sacrificar significativamente el rendimiento. Por otro lado, LoRA ofrece un enfoque eficiente para el fine-tuning, actualizando únicamente matrices de bajo rango en lugar de ajustar todos los parámetros del modelo, lo que reduce significativamente los requerimientos de memoria.\n",
    "\n",
    "Al combinar estas dos técnicas, se obtuvo QLoRA, un enfoque que permite afinar modelos previamente cuantizados de manera eficiente y precisa. Esto no solo reduce el costo computacional del fine-tuning, sino que también mantiene la calidad de las predicciones en tareas específicas. Esta combinación se demostró claramente en el ejemplo aplicado, donde el modelo ajustado conserva sus capacidades de inferencia mientras se adapta a tareas concretas de manera eficiente. La integración de la cuantización y LoRA subraya su importancia en el desarrollo de soluciones escalables y personalizadas, adaptadas a diversos contextos y restricciones de hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A55q6Wn5nAwB"
   },
   "source": [
    "## Bibliografía"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FY7hf5HnAwB"
   },
   "source": [
    "\n",
    "[1]\tY. Liu et al., «Understanding LLMs: A Comprehensive Overview from Training to Inference», 2024, arXiv. doi: 10.48550/ARXIV.2401.02038.\n",
    "\n",
    "[2]\tE. J. Hu et al., «LoRA: Low-Rank Adaptation of Large Language Models», 2021, arXiv. doi: 10.48550/ARXIV.2106.09685.\n",
    "\n",
    "[3]\tA. Vaswani et al., «Attention Is All You Need», 2017, arXiv. doi: 10.48550/ARXIV.1706.03762.\n",
    "\n",
    "[4]\tT. Dettmers, A. Pagnoni, A. Holtzman, y L. Zettlemoyer, «QLoRA: Efficient Finetuning of Quantized LLMs», 2023, arXiv. doi: 10.48550/ARXIV.2305.14314.\n",
    "\n",
    "[5]\tE. KIM, «Understanding Multi-Dimensionality in Vector Space Modeling», Pythonic Excursions. Accedido: 17 de noviembre de 2024. [En línea]. Disponible en: https://aegis4048.github.io/understanding_multi-dimensionality_in_vector_space_modeling\n",
    "\n",
    "[6]\tM. Jensen, K. Abbas, K. S. Abduljabbar, y J. Banks, «Automated Classification of Cell Level of HEp-2 Microscopic Images Using Deep Convolutional Neural Networks-Based Diameter Distance Features», JUCS - J. Univers. Comput. Sci., vol. 29, pp. 432-445, may 2023, doi: 10.3897/jucs.96293.\n",
    "\n",
    "[7]\t«OpenAI Platform». Accedido: 17 de noviembre de 2024. [En línea]. Disponible en: https://platform.openai.com\n",
    "\n",
    "[8] «YouTube-Blog/LLMs/qlora/qlora_example.ipynb at main · ShawhinT/YouTube-Blog», GitHub. . [En línea]. Disponible en: https://github.com/ShawhinT/YouTube-Blog/blob/main/LLMs/qlora/qlora_example.ipynb\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "013f84048f9c487a8c7df42e0b234d6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "02a8783a70c24c428f87e4863fa76de1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1cd395c812c94ce9945ae4c39c49ad5c",
       "IPY_MODEL_3f0a515d1a294247b270906b3b3018d9",
       "IPY_MODEL_f389dd6ea160482e91e6f8fa4214ec31"
      ],
      "layout": "IPY_MODEL_341a7e85c70046baac22ace0d1ed4d0b"
     }
    },
    "039c1df315ef4b168693135ae2c61258": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0655fdec80604cc6adfb0c9ade9a295d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07a8f85d57ea4a62ba8c706388f27202": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e3944fe6ef3c4b20b13770a2b265605d",
      "placeholder": "​",
      "style": "IPY_MODEL_cbda611225044d71b97fd8f1e29668a8",
      "value": " 51.0/51.0 [00:00&lt;00:00, 2.71kB/s]"
     }
    },
    "0a7297698ae545dd8669fa6471df1275": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0aa615ab2392473b8fe36de7ca8a2886": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6ea80e7fb6234594a10d9524c9eb1363",
       "IPY_MODEL_e34b1e50f94342d698bab8ca04c1f1d1",
       "IPY_MODEL_ec2e4951c55b4b44b21890e115724984"
      ],
      "layout": "IPY_MODEL_f4fcab9f948a40e082f5a11cf8a4f4ee"
     }
    },
    "0b3af3cbdde047beb92892986f3b957b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bd59d6bbeb54ff595ff0ae16568b426": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d080370f5984bb28fce48bb297e2dcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d35c45251094774b14e4de881e1d963": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec9ae05696cd443c8cc924b7143496fe",
      "placeholder": "​",
      "style": "IPY_MODEL_e365331202694cb8a93388e71d40e743",
      "value": " 1.80M/1.80M [00:00&lt;00:00, 19.2MB/s]"
     }
    },
    "11824195da674d4b9172a15f74173db0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11d9577c55cc4cfeb04481c14b50be98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15383431173b4b9797e2bbe6bccca21e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1655d6907d3542a2ab7129941d3976fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7eb23830ac7e4fe386de88d1df580b94",
      "placeholder": "​",
      "style": "IPY_MODEL_1e033afb0e51426f9e980cfe99fd46b4",
      "value": " 50/50 [00:00&lt;00:00, 941.36 examples/s]"
     }
    },
    "1a13144c57904ca387d2c2077a0281e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1cd395c812c94ce9945ae4c39c49ad5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6510685f788e476fa25a129e5f70aab3",
      "placeholder": "​",
      "style": "IPY_MODEL_039c1df315ef4b168693135ae2c61258",
      "value": "generation_config.json: 100%"
     }
    },
    "1e033afb0e51426f9e980cfe99fd46b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2018951f6ed34430bea95ec9c7943e70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "24523c635e44406889f397e7cabdf77d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_92a05c1ae0b34dd3b24e6e0f1b9739cb",
       "IPY_MODEL_2f710924d984463db963b2e66cb6c732",
       "IPY_MODEL_4e184f021fc04398bbd88fd54242463b"
      ],
      "layout": "IPY_MODEL_32116f9b72254e119da39c12804c94b3"
     }
    },
    "249e64cfd9134144bbff1b580c0db46b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_300c2b0ec6e64bdeb32e4c3f46eae6a2",
       "IPY_MODEL_7e40c71123bf4352bd7608dcd71a177b",
       "IPY_MODEL_abe0b71b6c2f45c692c848241c619f51"
      ],
      "layout": "IPY_MODEL_a6131f5372284c3ab190b4b2acee0dd5"
     }
    },
    "2a2f4f942e264de99073ad7cfc1f758e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7714416309834b5087e36eee3304f862",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f5ebe14ab49e4d02a047cffbb81afc8e",
      "value": 50
     }
    },
    "2c368d3d73ba4868b9eb0f81c9177d31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2da8416f089340fd8d56abe10cc34dea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f710924d984463db963b2e66cb6c732": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a13144c57904ca387d2c2077a0281e9",
      "max": 493443,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_434bc22c1be14c5e9072116bf0a70baa",
      "value": 493443
     }
    },
    "300c2b0ec6e64bdeb32e4c3f46eae6a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dea72b99a81944caa7f9d320bb94017d",
      "placeholder": "​",
      "style": "IPY_MODEL_5edcfea1779f4779826d31fc541c5672",
      "value": "config.json: 100%"
     }
    },
    "32116f9b72254e119da39c12804c94b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "341a7e85c70046baac22ace0d1ed4d0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3586f30e07bd4db48c17e9da2e396f99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b37687480b44dddafa47ecafd2f51c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b3a8de6ee284fdba4abe87f32d961bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f0a515d1a294247b270906b3b3018d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11d9577c55cc4cfeb04481c14b50be98",
      "max": 115,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e3e02036fded4e4d97a658af0d2ca8cd",
      "value": 115
     }
    },
    "434bc22c1be14c5e9072116bf0a70baa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "49ac19654898427c852d236f63091478": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8e6ca89ecc84a73871f4edd894c16bf",
      "placeholder": "​",
      "style": "IPY_MODEL_3586f30e07bd4db48c17e9da2e396f99",
      "value": " 50/50 [00:00&lt;00:00, 1113.03 examples/s]"
     }
    },
    "4bbc07a4c2fd4f56a74b590f136e9d5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_54928ac8fd8a435eb30587d9d97c2d81",
       "IPY_MODEL_f971f33d3d47413698152685393f4e63",
       "IPY_MODEL_49ac19654898427c852d236f63091478"
      ],
      "layout": "IPY_MODEL_97237fb5eec2464ca7a5034403da18eb"
     }
    },
    "4e184f021fc04398bbd88fd54242463b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b3af3cbdde047beb92892986f3b957b",
      "placeholder": "​",
      "style": "IPY_MODEL_89588702a550497f8c1d7989ddf69132",
      "value": " 493k/493k [00:00&lt;00:00, 21.3MB/s]"
     }
    },
    "54928ac8fd8a435eb30587d9d97c2d81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2da8416f089340fd8d56abe10cc34dea",
      "placeholder": "​",
      "style": "IPY_MODEL_fd5a98813da347af814a016259165f58",
      "value": "Map: 100%"
     }
    },
    "599d99ba1f2c4c7f948e822fbcf16eee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5a9a5b68d85e47a19b370fe94812afc6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ab2344195c94b61a46d38acd0a2ed2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15383431173b4b9797e2bbe6bccca21e",
      "max": 1795677,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f91d683a3a9047ea82662a2f29cffafd",
      "value": 1795677
     }
    },
    "5d3110ff623145869b65a8eb46e2aa9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5edcfea1779f4779826d31fc541c5672": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f9983b2333841d0ad889df6b3db54b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62571077099d4ff09411dd35016717d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "649f1c4765a948cfb0c607ebee23373e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f71fbfda1a3b4b43914c5678a372c8bc",
       "IPY_MODEL_6f58f7a4b76841d99021f5097f849a82",
       "IPY_MODEL_819c01f304234e65b6451bd1a70df392"
      ],
      "layout": "IPY_MODEL_64d3a42260464901831a950f61b1aa06"
     }
    },
    "64d3a42260464901831a950f61b1aa06": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6510685f788e476fa25a129e5f70aab3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67b4d30755554a02a626e42595eb88dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "68c679fd160641d09284d156871e3f3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e5cc4e6437d4080bef63a8eb5ade8e7",
       "IPY_MODEL_2a2f4f942e264de99073ad7cfc1f758e",
       "IPY_MODEL_1655d6907d3542a2ab7129941d3976fa"
      ],
      "layout": "IPY_MODEL_f9cbfb4c72c045e1adc3ca77a2d473e3"
     }
    },
    "69daa293a3ef49c6b84f428101bb812a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69dbae2e26cd4594a8e5a4c07ca0c4db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a6a15c9ad97426f802dda56edf0b033": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b0f0c96ddf24e1886ffe61c1e1657c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_830d794b6fd14d35a96f801582c4d48b",
       "IPY_MODEL_5ab2344195c94b61a46d38acd0a2ed2d",
       "IPY_MODEL_0d35c45251094774b14e4de881e1d963"
      ],
      "layout": "IPY_MODEL_a21242f9cf624306ae579ba5661ba8de"
     }
    },
    "6c0947f7c1a5478382054d8960e6f550": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d94d662dbbd543a1831918df97db549c",
       "IPY_MODEL_da5e8305f5ed447cade033cc9de0594e",
       "IPY_MODEL_07a8f85d57ea4a62ba8c706388f27202"
      ],
      "layout": "IPY_MODEL_0bd59d6bbeb54ff595ff0ae16568b426"
     }
    },
    "6e5cc4e6437d4080bef63a8eb5ade8e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b37687480b44dddafa47ecafd2f51c2",
      "placeholder": "​",
      "style": "IPY_MODEL_b225d860d5b641d186c89192087e1cee",
      "value": "Map: 100%"
     }
    },
    "6ea80e7fb6234594a10d9524c9eb1363": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f9983b2333841d0ad889df6b3db54b2",
      "placeholder": "​",
      "style": "IPY_MODEL_599d99ba1f2c4c7f948e822fbcf16eee",
      "value": "model.safetensors: 100%"
     }
    },
    "6f58f7a4b76841d99021f5097f849a82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7a7391e63b5484884146918f13e3f0d",
      "max": 420,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_013f84048f9c487a8c7df42e0b234d6a",
      "value": 420
     }
    },
    "6f97fdc36f08437fa5cfc1c6337dd902": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7714416309834b5087e36eee3304f862": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79312d6fc23947efb9f44ca599af10a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e40c71123bf4352bd7608dcd71a177b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e3f8deae1204b6eb24d315c80fb97bc",
      "max": 1521,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67b4d30755554a02a626e42595eb88dc",
      "value": 1521
     }
    },
    "7eb23830ac7e4fe386de88d1df580b94": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "819c01f304234e65b6451bd1a70df392": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a9a5b68d85e47a19b370fe94812afc6",
      "placeholder": "​",
      "style": "IPY_MODEL_69dbae2e26cd4594a8e5a4c07ca0c4db",
      "value": " 420/420 [00:00&lt;00:00, 24.4kB/s]"
     }
    },
    "830d794b6fd14d35a96f801582c4d48b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ebf03e06d9c94441ad15a86ad09d5d6f",
      "placeholder": "​",
      "style": "IPY_MODEL_ab23f1a7e5ac4cb791d13bc66377f67f",
      "value": "tokenizer.json: 100%"
     }
    },
    "889dc00d38414e58bb833d9670a6db6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0564fcb36374c36b156899559c84fb5",
      "placeholder": "​",
      "style": "IPY_MODEL_8f11202ce6014764be95c37a48aa3b23",
      "value": " 1.60k/1.60k [00:00&lt;00:00, 69.2kB/s]"
     }
    },
    "89588702a550497f8c1d7989ddf69132": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8988edcc5c5342e6a245cbe42ae6d849": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f11202ce6014764be95c37a48aa3b23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92a05c1ae0b34dd3b24e6e0f1b9739cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a7297698ae545dd8669fa6471df1275",
      "placeholder": "​",
      "style": "IPY_MODEL_5d3110ff623145869b65a8eb46e2aa9a",
      "value": "tokenizer.model: 100%"
     }
    },
    "9504c76de3764aa68ab04202131770ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "970dce35ee0d41e8b5c3bf7f70b30e91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "97237fb5eec2464ca7a5034403da18eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9bcd2145e0734418b0a481276904e303": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e3f8deae1204b6eb24d315c80fb97bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a21242f9cf624306ae579ba5661ba8de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6131f5372284c3ab190b4b2acee0dd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ab23f1a7e5ac4cb791d13bc66377f67f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "abe0b71b6c2f45c692c848241c619f51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11824195da674d4b9172a15f74173db0",
      "placeholder": "​",
      "style": "IPY_MODEL_fa196e755e0e4877bb4d571d0c9523bb",
      "value": " 1.52k/1.52k [00:00&lt;00:00, 57.3kB/s]"
     }
    },
    "b077340d90c640048426ab1eea849fcc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b225d860d5b641d186c89192087e1cee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b380646d0a9f4b43be488bb18d7b10d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b7a7391e63b5484884146918f13e3f0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7f1a9116bd941db85d4be66ea5f51fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8e6ca89ecc84a73871f4edd894c16bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b94b60ec5fdd4f9f8ecc0baaed6bd1b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e3d4ea757d844f09a81751a96ec9dc35",
       "IPY_MODEL_da2cfc62f4d045dc8767d46ace81fa38",
       "IPY_MODEL_889dc00d38414e58bb833d9670a6db6c"
      ],
      "layout": "IPY_MODEL_b077340d90c640048426ab1eea849fcc"
     }
    },
    "c27e604baacd4e0eb600b41be40dc40e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbda611225044d71b97fd8f1e29668a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d94d662dbbd543a1831918df97db549c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee4ac058e10c4edb85efff6d0ac45b7a",
      "placeholder": "​",
      "style": "IPY_MODEL_9504c76de3764aa68ab04202131770ba",
      "value": "added_tokens.json: 100%"
     }
    },
    "da2cfc62f4d045dc8767d46ace81fa38": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bcd2145e0734418b0a481276904e303",
      "max": 1598,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2c368d3d73ba4868b9eb0f81c9177d31",
      "value": 1598
     }
    },
    "da5e8305f5ed447cade033cc9de0594e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0655fdec80604cc6adfb0c9ade9a295d",
      "max": 51,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b380646d0a9f4b43be488bb18d7b10d9",
      "value": 51
     }
    },
    "dea72b99a81944caa7f9d320bb94017d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0564fcb36374c36b156899559c84fb5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e34b1e50f94342d698bab8ca04c1f1d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62571077099d4ff09411dd35016717d9",
      "max": 4158694984,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_970dce35ee0d41e8b5c3bf7f70b30e91",
      "value": 4158694984
     }
    },
    "e365331202694cb8a93388e71d40e743": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e3944fe6ef3c4b20b13770a2b265605d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3d4ea757d844f09a81751a96ec9dc35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c27e604baacd4e0eb600b41be40dc40e",
      "placeholder": "​",
      "style": "IPY_MODEL_69daa293a3ef49c6b84f428101bb812a",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "e3e02036fded4e4d97a658af0d2ca8cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ebf03e06d9c94441ad15a86ad09d5d6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec2e4951c55b4b44b21890e115724984": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8988edcc5c5342e6a245cbe42ae6d849",
      "placeholder": "​",
      "style": "IPY_MODEL_79312d6fc23947efb9f44ca599af10a0",
      "value": " 4.16G/4.16G [01:38&lt;00:00, 42.4MB/s]"
     }
    },
    "ec9ae05696cd443c8cc924b7143496fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee4ac058e10c4edb85efff6d0ac45b7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f389dd6ea160482e91e6f8fa4214ec31": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0d080370f5984bb28fce48bb297e2dcd",
      "placeholder": "​",
      "style": "IPY_MODEL_6a6a15c9ad97426f802dda56edf0b033",
      "value": " 115/115 [00:00&lt;00:00, 6.75kB/s]"
     }
    },
    "f4fcab9f948a40e082f5a11cf8a4f4ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5ebe14ab49e4d02a047cffbb81afc8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f71fbfda1a3b4b43914c5678a372c8bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7f1a9116bd941db85d4be66ea5f51fc",
      "placeholder": "​",
      "style": "IPY_MODEL_6f97fdc36f08437fa5cfc1c6337dd902",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "f91d683a3a9047ea82662a2f29cffafd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f971f33d3d47413698152685393f4e63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b3a8de6ee284fdba4abe87f32d961bc",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2018951f6ed34430bea95ec9c7943e70",
      "value": 50
     }
    },
    "f9cbfb4c72c045e1adc3ca77a2d473e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa196e755e0e4877bb4d571d0c9523bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd5a98813da347af814a016259165f58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
